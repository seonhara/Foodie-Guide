import openai
import os
from dotenv import load_dotenv
load_dotenv() 

# OpenAI
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=OPENAI_API_KEY) 

CHAT_NORMAL = "ì¼ë°˜ ëŒ€í™”"
CHAT_ASKMORE = "ìŒì‹ì  ë©”ë‰´ ì¶”ì²œ ì—†ì´ ì¼ë°˜ ì§ˆë¬¸"
CHAT_MENURCMD = "ìŒì‹ì  ë©”ë‰´ ì¶”ì²œ"
CHAT_MENURCMD_MYCOND = "ë³¸ì¸ ìƒíƒœ ì•Œë¦¼ ë° ê´€ë ¨ ìŒì‹ì  ë©”ë‰´ ì¶”ì²œ"
CHAT_MENURCMD_MYTASTE = "ë¨¹ê³  ì‹¶ì€ ìŒì‹ì  ë©”ë‰´ ì„¤ëª… ë° ì¶”ì²œ"
CHAT_MENURCMD_RESTAURANT = "ì‹ë‹¹ ì¶”ì²œ ìš”ì²­ ë˜ëŠ” íŠ¹ì • ë©”ë‰´ ì–¸ê¸‰"

CHAT_TYPES = [CHAT_NORMAL, CHAT_ASKMORE, CHAT_MENURCMD, CHAT_MENURCMD_MYCOND, CHAT_MENURCMD_MYTASTE, CHAT_MENURCMD_RESTAURANT]


def classify_request(user_input):
    string_types = "".join([f"- {item}\n" for item in CHAT_TYPES])
    prompt = f"""
    ë‹¤ìŒ ë¬¸ìž¥ì´ ì–´ë–¤ ìœ í˜•ì¸ì§€ ë¶„ë¥˜í•´ì¤˜. ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:
    {string_types}
    
    ë¬¸ìž¥: "{user_input}"
    
    ë‹µë³€ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ í•´ì¤˜:
    
    ë¶„ë¥˜: ì¹´í…Œê³ ë¦¬ëª…
    
    """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "ë„ˆëŠ” ìž…ë ¥ëœ ë¬¸ìž¥ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” AIì•¼."},
                  {"role": "user", "content": prompt}],
        temperature=0  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
    )

    # ì‘ë‹µì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    result_text = response.choices[0].message.content
    category = result_text.split("ë¶„ë¥˜: ")[-1].strip()
    print(category)
    
    return category

def extract_and_search_menu(text):
    prompt = f"""
    ë‹¤ìŒ ë¬¸ìž¥ì„ ì½ê³  ë¬¸ìž¥ì—ì„œ ì¶”ì²œí•˜ê±°ë‚˜ ë¨¹ê¸° ì¢‹ì€ ë©”ë‰´ë¥¼ ì¶”ì¶œí•´ì¤˜:
    
    ë¬¸ìž¥: "{text}"
    
    ë‹µë³€ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ í•´ì¤˜:
    
    ë‹µë³€: ë©”ë‰´1,ë©”ë‰´2,ë©”ë‰´3,ë©”ë‰´4,ë©”ë‰´5,...
    
    """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "ë„ˆëŠ” ìž…ë ¥ëœ ë¬¸ìž¥ì—ì„œ ì¶”ì²œí•˜ëŠ” ë©”ë‰´ë‚˜ ë¨¹ê¸° ì¢‹ì€ ë©”ë‰´ë¥¼ ì¶”ì¶œí•˜ëŠ” AIì•¼."},
                  {"role": "user", "content": prompt}],
        temperature=0  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
    )

    # ì‘ë‹µì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    result_text = response.choices[0].message.content
    menus = result_text.split(",")
        
    return menus

def chat(user_message):
    messages = []
    messages.append({"role": "user", "content": user_message})
    category = classify_request(user_message)
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        bot_reply = response.choices[0].message.content
    except Exception as e:
        bot_reply = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    print("ðŸš¨ðŸš¨ðŸš¨ðŸš¨ bot_reply", bot_reply)

    link_exist = False
    if category in [CHAT_MENURCMD, CHAT_MENURCMD_MYTASTE, CHAT_MENURCMD_MYCOND, CHAT_MENURCMD_RESTAURANT]:
        menus = extract_and_search_menu(bot_reply)
        link_exist = True
    else:
        menus = []
        link_exist = False
    print(menus)
    if len(menus) > 0:
        add_str = "[{}]".format(",".join(menus))
    
    return {"reply": bot_reply, "menus": ",".join(menus), "link_exist": link_exist, "category": category}