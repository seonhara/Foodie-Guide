import pickle
from langchain_text_splitters import RecursiveCharacterTextSplitter
import numpy as np
import openai
import faiss
import os
from tqdm import tqdm

import dotenv
dotenv.load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")

class RAG(object):

    HEALTH = "health"
    INGREDIENTS = "ingredients"

    def __init__(self, filename = HEALTH):
        self.filename = filename
        self.index = None
        self.chunks = None

    def get_embedding(self, texts):
        response = openai.embeddings.create(
            model="text-embedding-3-small",
            input=texts
        )
        
        return [item.embedding for item in response.data]
    
    def get_embedding_one(self, text):
        return self.get_embedding(text)[0]
    
    def batched_embeddings(self, chunks, epoch_size=1000): # For ë¬¸ìœ¼ë¡œ batch ì—†ì´ ì²˜ë¦¬í•˜ë©´ ë„ˆë¬´ ë§ì´ ìš”ì²­í•´ì„œ batch í•¨ìˆ˜ ë§Œë“¬ 
        """
        chunks: List[str] - ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ì¡°ê°ë“¤
        epoch_size: int - í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ í…ìŠ¤íŠ¸ ìˆ˜ (ë°°ì¹˜ í¬ê¸°)
        """
        all_embeddings = []

        # ì´ epoch ìˆ˜ ê³„ì‚°
        total = len(chunks)
        for i in tqdm(range(0, total, epoch_size), desc="Embedding batches"):
            batch = chunks[i:i+epoch_size]
            
            # get_embeddingì€ í•œ ë²ˆì— ì—¬ëŸ¬ ê°œì˜ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ë¼ê³  ê°€ì •
            batch_embeddings = self.get_embedding(batch)
            
            # ê²°ê³¼ í•©ì¹˜ê¸°
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings

    def save_vector_index(self):
        with open(f"docs/{self.filename}.txt", "r", encoding="utf-8") as f:
            raw_text = f.read()
        print("âœ…1/5 íŒŒì¼ í˜¸ì¶œ ì™„ë£Œ!")

        # 2. í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_text(raw_text)
        print("âœ…2/5 ì²­í¬ ìƒì„± ì™„ë£Œ!")

        # 3. ì²­í¬ ì„ë² ë”©
        N = len(chunks)
        print("ì²­í¬ ê°œìˆ˜:", N)
        embeddings = self.batched_embeddings(chunks)
        embeddings_np = np.array(embeddings).astype("float32")
        print("âœ…3/5 ì²­í¬ ì„ë² ë”© ì™„ë£Œ!")

        # 4. FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
        dimension = len(embeddings[0])
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings_np)

        faiss.write_index(index, f"vector_store/index_{self.filename}.faiss")
        print("âœ…4/5 FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")

        # ğŸ‘‰ ì²­í¬ë„ í•¨ê»˜ ì €ì¥
        with open(f"vector_store/chunks_{self.filename}.pkl", "wb") as f:
            pickle.dump(chunks, f)

        print("âœ…5/5 ì„ë² ë”© ì €ì¥ ì™„ë£Œ!")

    def load_vector_index(self):
        self.index = faiss.read_index(f"vector_store/index_{self.filename}.faiss")

        with open(f"vector_store/chunks_{self.filename}.pkl", "rb") as f:
            self.chunks = pickle.load(f)
    
    def search_and_wrap(self, question):
        query_embedding = np.array([self.get_embedding_one(question)]).astype("float32")
        if self.index is not None:
            D, I = self.index.search(query_embedding, k=5)
            retrieved_chunks =  [self.chunks[i] for i in I[0]]
            print("[ì¶”ê°€ëœ RAG ì²­í¬]", retrieved_chunks)
            prompt = "ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì¤˜:\n\n"
            prompt += "\n\n".join(retrieved_chunks)
            prompt += f"\n\nì§ˆë¬¸: {question}"
        else:
            prompt = question
        return prompt